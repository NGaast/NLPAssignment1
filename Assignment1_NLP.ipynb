{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tomva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\tomva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tomva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tomva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\tomva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_df = pd.read_csv(\"Data/AAPL.csv\")\n",
    "news_df = pd.read_csv(\"Data/us_equities_news_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>release_date</th>\n",
       "      <th>provider</th>\n",
       "      <th>url</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221515</td>\n",
       "      <td>NIO</td>\n",
       "      <td>Why Shares of Chinese Electric Car Maker NIO A...</td>\n",
       "      <td>news</td>\n",
       "      <td>What s happening\\nShares of Chinese electric c...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://invst.ly/pigqi</td>\n",
       "      <td>2060327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221516</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO only consumer gainer  Workhorse Group amon...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pje9c</td>\n",
       "      <td>2062196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221517</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO leads consumer gainers  Beyond Meat and Ma...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   14   Village Farms In...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pifmv</td>\n",
       "      <td>2060249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221518</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO  NVAX among premarket gainers</td>\n",
       "      <td>news</td>\n",
       "      <td>Cemtrex  NASDAQ CETX   85  after FY results \\n...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/picu8</td>\n",
       "      <td>2060039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221519</td>\n",
       "      <td>NIO</td>\n",
       "      <td>PLUG  NIO among premarket gainers</td>\n",
       "      <td>news</td>\n",
       "      <td>aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://seekingalpha.com/news/3529772-plug-nio...</td>\n",
       "      <td>2053096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221508</th>\n",
       "      <td>443024</td>\n",
       "      <td>T</td>\n",
       "      <td>Crude And Steel Still In Sync</td>\n",
       "      <td>opinion</td>\n",
       "      <td>We have been reporting on the trade off betwee...</td>\n",
       "      <td>2012-10-04</td>\n",
       "      <td>Ivan Kitov</td>\n",
       "      <td>https://www.investing.com/analysis/crude-and-s...</td>\n",
       "      <td>138733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221509</th>\n",
       "      <td>443025</td>\n",
       "      <td>T</td>\n",
       "      <td>Forget AT T  This Is The Telecom Stock You Sho...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>It s the largest cell phone provider in the wo...</td>\n",
       "      <td>2012-05-30</td>\n",
       "      <td>StreetAuthority</td>\n",
       "      <td>https://www.investing.com/analysis/forget-at-t...</td>\n",
       "      <td>124829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221510</th>\n",
       "      <td>443026</td>\n",
       "      <td>T</td>\n",
       "      <td>Wall Street Exposed   Part 3   How Dividends C...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Before we dicuss how the mechanism of dividend...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>Portfolio Cafe</td>\n",
       "      <td>https://www.investing.com/analysis/wall-street...</td>\n",
       "      <td>129651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221511</th>\n",
       "      <td>443027</td>\n",
       "      <td>T</td>\n",
       "      <td>Weighing The Week Ahead  It s All About Jobs</td>\n",
       "      <td>opinion</td>\n",
       "      <td>From start to finish  the coming week will hav...</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>Jeff Miller</td>\n",
       "      <td>https://www.investing.com/analysis/weighing-th...</td>\n",
       "      <td>134926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221512</th>\n",
       "      <td>443028</td>\n",
       "      <td>T</td>\n",
       "      <td>Leap Wireless  LEAP    JPM Note and AT T   T M...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Leap Wireless International  Inc   Leap  is a ...</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>Ophir Gottlieb</td>\n",
       "      <td>https://www.investing.com/analysis/leap-wirele...</td>\n",
       "      <td>110079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221513 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id ticker                                              title  \\\n",
       "0       221515    NIO  Why Shares of Chinese Electric Car Maker NIO A...   \n",
       "1       221516    NIO  NIO only consumer gainer  Workhorse Group amon...   \n",
       "2       221517    NIO  NIO leads consumer gainers  Beyond Meat and Ma...   \n",
       "3       221518    NIO                  NIO  NVAX among premarket gainers   \n",
       "4       221519    NIO                  PLUG  NIO among premarket gainers   \n",
       "...        ...    ...                                                ...   \n",
       "221508  443024      T                     Crude And Steel Still In Sync    \n",
       "221509  443025      T  Forget AT T  This Is The Telecom Stock You Sho...   \n",
       "221510  443026      T  Wall Street Exposed   Part 3   How Dividends C...   \n",
       "221511  443027      T       Weighing The Week Ahead  It s All About Jobs   \n",
       "221512  443028      T  Leap Wireless  LEAP    JPM Note and AT T   T M...   \n",
       "\n",
       "       category                                            content  \\\n",
       "0          news  What s happening\\nShares of Chinese electric c...   \n",
       "1          news  Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   \n",
       "2          news  Gainers  NIO  NYSE NIO   14   Village Farms In...   \n",
       "3          news  Cemtrex  NASDAQ CETX   85  after FY results \\n...   \n",
       "4          news  aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...   \n",
       "...         ...                                                ...   \n",
       "221508  opinion  We have been reporting on the trade off betwee...   \n",
       "221509  opinion  It s the largest cell phone provider in the wo...   \n",
       "221510  opinion  Before we dicuss how the mechanism of dividend...   \n",
       "221511  opinion  From start to finish  the coming week will hav...   \n",
       "221512  opinion  Leap Wireless International  Inc   Leap  is a ...   \n",
       "\n",
       "       release_date         provider  \\\n",
       "0        2020-01-15  The Motley Fool   \n",
       "1        2020-01-18    Seeking Alpha   \n",
       "2        2020-01-15    Seeking Alpha   \n",
       "3        2020-01-15    Seeking Alpha   \n",
       "4        2020-01-06    Seeking Alpha   \n",
       "...             ...              ...   \n",
       "221508   2012-10-04       Ivan Kitov   \n",
       "221509   2012-05-30  StreetAuthority   \n",
       "221510   2012-07-16   Portfolio Cafe   \n",
       "221511   2012-09-02      Jeff Miller   \n",
       "221512   2011-12-31   Ophir Gottlieb   \n",
       "\n",
       "                                                      url  article_id  \n",
       "0                                  https://invst.ly/pigqi     2060327  \n",
       "1                                  https://invst.ly/pje9c     2062196  \n",
       "2                                  https://invst.ly/pifmv     2060249  \n",
       "3                                  https://invst.ly/picu8     2060039  \n",
       "4       https://seekingalpha.com/news/3529772-plug-nio...     2053096  \n",
       "...                                                   ...         ...  \n",
       "221508  https://www.investing.com/analysis/crude-and-s...      138733  \n",
       "221509  https://www.investing.com/analysis/forget-at-t...      124829  \n",
       "221510  https://www.investing.com/analysis/wall-street...      129651  \n",
       "221511  https://www.investing.com/analysis/weighing-th...      134926  \n",
       "221512  https://www.investing.com/analysis/leap-wirele...      110079  \n",
       "\n",
       "[221513 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in news_df 'content' column: 516\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing Steps\n",
    "\n",
    "# Apple dataframe\n",
    "# Add price_higher column based on:\n",
    "# Close > Open = 1\n",
    "# Close <= Open = 0\n",
    "apple_df['price_higher'] = apple_df.apply(lambda row: 1 if row['Close'] > row['Open'] else 0, axis=1)\n",
    "\n",
    "# News dataframe\n",
    "# Find and delete duplicate content\n",
    "print(f\"Duplicate rows in news_df 'content' column: {news_df['content'].duplicated().sum()}\")\n",
    "news_df.drop_duplicates('content', inplace=True)\n",
    "\n",
    "# Filter news content based on Apple stock\n",
    "news_df = news_df[news_df['ticker'] == 'AAPL']\n",
    "\n",
    "# Join price_higher column with news dataframe based on date\n",
    "news_df = news_df.merge(apple_df[['Date', 'price_higher']], left_on='release_date', right_on='Date')\n",
    "news_df = news_df.drop(columns=['Date'])\n",
    "\n",
    "# Convert release_date to datetime type\n",
    "news_df['release_date'] = pd.to_datetime(news_df['release_date'])\n",
    "\n",
    "news_df['content'] = news_df['content'].apply(lambda x: ' '.join(x.split(' \\n')))\n",
    "news_df['content'] = news_df['content'].apply(lambda x: ' '.join(list(filter(None, [i.strip(' ') for i in x.split('\\r\\n')]))))\n",
    "news_df['words_amount'] = news_df.apply(lambda row: len(row['content'].split(\" \")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of Apple articles is: 17624\n",
      "The total amount of words for all articles is: 12740260\n",
      "The amount unique words for all articles is: 126590\n",
      "The average amount of words per article is: 723\n",
      "9529 8095\n"
     ]
    }
   ],
   "source": [
    "print(f\"The amount of Apple articles is: {str(len(news_df['article_id'].unique()))}\")\n",
    "print(f\"The total amount of words for all articles is: {str(len(' '.join(news_df['content']).split(' ')))}\")\n",
    "print(f\"The amount unique words for all articles is: {str(len(set(' '.join(news_df['content']).split(' '))))}\")\n",
    "print(f\"The average amount of words per article is: {str(round(news_df['words_amount'].mean()))}\")\n",
    "\n",
    "# TEST: Distribution of price_higher\n",
    "days_higher = news_df[news_df['price_higher'] == 1]['price_higher'].count()\n",
    "days_lower = news_df[news_df['price_higher'] == 0]['price_higher'].count()\n",
    "\n",
    "print(days_higher, days_lower)\n",
    "#Lexical richness bekijk https://pypi.org/project/lexicalrichness/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate content by date\n",
    "news_df.groupby('release_date').agg({'content': '.'.join})\n",
    "news_df['content'] = news_df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lexical_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jpmorgan, lifts, apple, aapl, target, ahead, ...</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[kim, khan, investing, com, faang, stocks, pre...</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[chuck, mikolajczak, new, york, reuters, u, st...</td>\n",
       "      <td>0.717224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[two, best, performing, tech, stocks, set, rep...</td>\n",
       "      <td>0.684601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[yasin, ebrahim, kim, khan, apple, readies, ea...</td>\n",
       "      <td>0.702532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17619</th>\n",
       "      <td>[stock, market, difficult, one, traders, inves...</td>\n",
       "      <td>0.659432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17620</th>\n",
       "      <td>[tsx, index, leading, canadian, stocks, outper...</td>\n",
       "      <td>0.557616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>[europe, flares, summer, heat, continues, summ...</td>\n",
       "      <td>0.705521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17622</th>\n",
       "      <td>[last, quarter, apple, aapl, reported, best, q...</td>\n",
       "      <td>0.482667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17623</th>\n",
       "      <td>[may, look, like, spider, web, mishmash, trend...</td>\n",
       "      <td>0.650862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17624 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  lexical_div\n",
       "0      [jpmorgan, lifts, apple, aapl, target, ahead, ...     0.857143\n",
       "1      [kim, khan, investing, com, faang, stocks, pre...     0.729167\n",
       "2      [chuck, mikolajczak, new, york, reuters, u, st...     0.717224\n",
       "3      [two, best, performing, tech, stocks, set, rep...     0.684601\n",
       "4      [yasin, ebrahim, kim, khan, apple, readies, ea...     0.702532\n",
       "...                                                  ...          ...\n",
       "17619  [stock, market, difficult, one, traders, inves...     0.659432\n",
       "17620  [tsx, index, leading, canadian, stocks, outper...     0.557616\n",
       "17621  [europe, flares, summer, heat, continues, summ...     0.705521\n",
       "17622  [last, quarter, apple, aapl, reported, best, q...     0.482667\n",
       "17623  [may, look, like, spider, web, mishmash, trend...     0.650862\n",
       "\n",
       "[17624 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "test_news_df = news_df.copy()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = text.split(' ')\n",
    "    return tokens\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    test = [token for token in tokens if (token != '' and token not in english_stopwords) and token.isalpha()]\n",
    "    return test\n",
    "\n",
    "def join_tokens(tokens):\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def calc_lexical_div(tokens):\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "# TODO\n",
    "words_to_be_removed = ['apple', 'aapl']\n",
    "\n",
    "# Tokenize content string\n",
    "test_news_df['content'] = test_news_df['content'].apply(tokenize)\n",
    "# Remove stopwords, empty tokens and punctuation/numbers\n",
    "test_news_df['tokens'] = test_news_df['content'].apply(clean_tokens)\n",
    "# Join tokens into string\n",
    "test_news_df['content'] = test_news_df['tokens'].apply(join_tokens)\n",
    "# Calculate lexical diversity per date\n",
    "test_news_df['lexical_div'] = test_news_df['tokens'].apply(calc_lexical_div)\n",
    "\n",
    "test_news_df[['tokens', 'lexical_div']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pervades': 'pervades',\n",
       " 'fetishism': 'fetishism',\n",
       " 'drumroll': 'drumroll',\n",
       " 'achieves': 'achieves',\n",
       " 'confrontations': 'confrontation',\n",
       " 'synovial': 'synovial',\n",
       " 'fist': 'fist',\n",
       " 'agx': 'agx',\n",
       " 'detailsthis': 'detailsthis',\n",
       " 'aixgn': 'aixgn',\n",
       " 'pharmacodynamic': 'pharmacodynamic',\n",
       " 'trrpx': 'trrpx',\n",
       " 'dvmt': 'dvmt',\n",
       " 'dalvin': 'dalvin',\n",
       " 'stringency': 'stringency',\n",
       " 'hiroshima': 'hiroshima',\n",
       " 'peerlogix': 'peerlogix',\n",
       " 'hearty': 'hearty',\n",
       " 'luncheon': 'luncheon',\n",
       " 'hpi': 'hpi',\n",
       " 'cancerper': 'cancerper',\n",
       " 'moise': 'moise',\n",
       " 'antimicrobial': 'antimicrobial',\n",
       " 'minivans': 'minivan',\n",
       " 'dieselgate': 'dieselgate',\n",
       " 'fafdx': 'fafdx',\n",
       " 'miners': 'miner',\n",
       " 'tightens': 'tightens',\n",
       " 'withhold': 'withhold',\n",
       " 'dozing': 'doze',\n",
       " 'standardized': 'standardized',\n",
       " 'scholars': 'scholar',\n",
       " 'orderly': 'orderly',\n",
       " 'propelling': 'propel',\n",
       " 'undermentioned': 'undermentioned',\n",
       " 'noncompetitive': 'noncompetitive',\n",
       " 'linelodging': 'linelodging',\n",
       " 'curious': 'curious',\n",
       " 'pomegranate': 'pomegranate',\n",
       " 'signified': 'signify',\n",
       " 'hagan': 'hagan',\n",
       " 'verisk': 'verisk',\n",
       " 'reactionary': 'reactionary',\n",
       " 'fsiv': 'fsiv',\n",
       " 'processingweak': 'processingweak',\n",
       " 'headlinesavon': 'headlinesavon',\n",
       " 'browsed': 'browse',\n",
       " 'cdtx': 'cdtx',\n",
       " 'rheinische': 'rheinische',\n",
       " 'cpsg': 'cpsg',\n",
       " 'resnick': 'resnick',\n",
       " 'prevents': 'prevents',\n",
       " 'abuzz': 'abuzz',\n",
       " 'reevaluated': 'reevaluate',\n",
       " 'fiction': 'fiction',\n",
       " 'playjohnson': 'playjohnson',\n",
       " 'defective': 'defective',\n",
       " 'immune': 'immune',\n",
       " 'doctoring': 'doctor',\n",
       " 'genotyping': 'genotyping',\n",
       " 'carlquintanilla': 'carlquintanilla',\n",
       " 'ingvild': 'ingvild',\n",
       " 'estimateon': 'estimateon',\n",
       " 'preferable': 'preferable',\n",
       " 'treehouse': 'treehouse',\n",
       " 'cass': 'ca',\n",
       " 'wag': 'wag',\n",
       " 'gepetrol': 'gepetrol',\n",
       " 'gmlacefcefh': 'gmlacefcefh',\n",
       " 'aglimpse': 'aglimpse',\n",
       " 'inflators': 'inflator',\n",
       " 'koolaburra': 'koolaburra',\n",
       " 'sapinsider': 'sapinsider',\n",
       " 'aidthe': 'aidthe',\n",
       " 'painted': 'paint',\n",
       " 'djamena': 'djamena',\n",
       " 'wknd': 'wknd',\n",
       " 'occlusion': 'occlusion',\n",
       " 'ditching': 'ditch',\n",
       " 'utilitiescenterpoint': 'utilitiescenterpoint',\n",
       " 'ozark': 'ozark',\n",
       " 'parm': 'parm',\n",
       " 'thursdayoil': 'thursdayoil',\n",
       " 'considerkinross': 'considerkinross',\n",
       " 'materials': 'material',\n",
       " 'membership': 'membership',\n",
       " 'respectability': 'respectability',\n",
       " 'quantify': 'quantify',\n",
       " 'orderup': 'orderup',\n",
       " 'alessandro': 'alessandro',\n",
       " 'interconnect': 'interconnect',\n",
       " 'portfolionextera': 'portfolionextera',\n",
       " 'electric': 'electric',\n",
       " 'si': 'si',\n",
       " 'subsegments': 'subsegments',\n",
       " 'pantagraph': 'pantagraph',\n",
       " 'liquiditythe': 'liquiditythe',\n",
       " 'quareter': 'quareter',\n",
       " 'degrading': 'degrade',\n",
       " 'glacial': 'glacial',\n",
       " 'reade': 'reade',\n",
       " 'splurging': 'splurge',\n",
       " 'rover': 'rover',\n",
       " 'craps': 'crap',\n",
       " 'schostek': 'schostek',\n",
       " 'alinity': 'alinity',\n",
       " 'sheetfor': 'sheetfor',\n",
       " 'meggers': 'meggers',\n",
       " 'ores': 'ores',\n",
       " 'longines': 'longines',\n",
       " 'motorbike': 'motorbike',\n",
       " 'servicenow': 'servicenow',\n",
       " 'stockswhile': 'stockswhile',\n",
       " 'ige': 'ige',\n",
       " 'reph': 'reph',\n",
       " 'jumpfollowing': 'jumpfollowing',\n",
       " 'dry': 'dry',\n",
       " 'zeros': 'zero',\n",
       " 'compound': 'compound',\n",
       " 'naumann': 'naumann',\n",
       " 'ticket': 'ticket',\n",
       " 'gladdening': 'gladden',\n",
       " 'jeanny': 'jeanny',\n",
       " 'twiggs': 'twiggs',\n",
       " 'renovated': 'renovate',\n",
       " 'robovacs': 'robovacs',\n",
       " 'frankenstein': 'frankenstein',\n",
       " 'qlta': 'qlta',\n",
       " 'neutralization': 'neutralization',\n",
       " 'together': 'together',\n",
       " 'spaceship': 'spaceship',\n",
       " 'ladders': 'ladder',\n",
       " 'scmwy': 'scmwy',\n",
       " 'swimmers': 'swimmer',\n",
       " 'convict': 'convict',\n",
       " 'ong': 'ong',\n",
       " 'baeb': 'baeb',\n",
       " 'manage': 'manage',\n",
       " 'rae': 'rae',\n",
       " 'kuka': 'kuka',\n",
       " 'dsurmodics': 'dsurmodics',\n",
       " 'transmit': 'transmit',\n",
       " 'athenaclinicals': 'athenaclinicals',\n",
       " 'cbrl': 'cbrl',\n",
       " 'empanelled': 'empanel',\n",
       " 'xlzs': 'xlzs',\n",
       " 'servicesat': 'servicesat',\n",
       " 'wintertime': 'wintertime',\n",
       " 'kuomintang': 'kuomintang',\n",
       " 'pliable': 'pliable',\n",
       " 'limp': 'limp',\n",
       " 'greenfield': 'greenfield',\n",
       " 'qdel': 'qdel',\n",
       " 'fujitsu': 'fujitsu',\n",
       " 'amplifier': 'amplifier',\n",
       " 'tonnochy': 'tonnochy',\n",
       " 'befitting': 'befit',\n",
       " 'benefitsat': 'benefitsat',\n",
       " 'vatiquinone': 'vatiquinone',\n",
       " 'werner': 'werner',\n",
       " 'ctbi': 'ctbi',\n",
       " 'gau': 'gau',\n",
       " 'zenbo': 'zenbo',\n",
       " 'luo': 'luo',\n",
       " 'xingtai': 'xingtai',\n",
       " 'usthe': 'usthe',\n",
       " 'andintel': 'andintel',\n",
       " 'outlooksanderson': 'outlooksanderson',\n",
       " 'yashaswini': 'yashaswini',\n",
       " 'starway': 'starway',\n",
       " 'publ': 'publ',\n",
       " 'greener': 'greener',\n",
       " 'wary': 'wary',\n",
       " 'neuquen': 'neuquen',\n",
       " 'coin': 'coin',\n",
       " 'lockup': 'lockup',\n",
       " 'lollipop': 'lollipop',\n",
       " 'aged': 'age',\n",
       " 'bamxf': 'bamxf',\n",
       " 'misapplied': 'misapply',\n",
       " 'relugolix': 'relugolix',\n",
       " 'designan': 'designan',\n",
       " 'phytel': 'phytel',\n",
       " 'faamng': 'faamng',\n",
       " 'transitional': 'transitional',\n",
       " 'nowit': 'nowit',\n",
       " 'yearyields': 'yearyields',\n",
       " 'picksge': 'picksge',\n",
       " 'impression': 'impression',\n",
       " 'epilepsies': 'epilepsy',\n",
       " 'auctioneers': 'auctioneer',\n",
       " 'hollywood': 'hollywood',\n",
       " 'distinguishing': 'distinguish',\n",
       " 'spotsdespite': 'spotsdespite',\n",
       " 'bungie': 'bungie',\n",
       " 'namgyal': 'namgyal',\n",
       " 'thaad': 'thaad',\n",
       " 'retrials': 'retrial',\n",
       " 'anacetrapib': 'anacetrapib',\n",
       " 'flagrant': 'flagrant',\n",
       " 'pomalyst': 'pomalyst',\n",
       " 'medina': 'medina',\n",
       " 'edibles': 'edibles',\n",
       " 'hbhc': 'hbhc',\n",
       " 'aq': 'aq',\n",
       " 'kddi': 'kddi',\n",
       " 'direxion': 'direxion',\n",
       " 'bytes': 'bytes',\n",
       " 'inclement': 'inclement',\n",
       " 'reaffirms': 'reaffirms',\n",
       " 'bielefeld': 'bielefeld',\n",
       " 'woofers': 'woofer',\n",
       " 'memorial': 'memorial',\n",
       " 'valspar': 'valspar',\n",
       " 'mub': 'mub',\n",
       " 'rim': 'rim',\n",
       " 'waukee': 'waukee',\n",
       " 'woodman': 'woodman',\n",
       " 'spaceundoubtedly': 'spaceundoubtedly',\n",
       " 'cooperates': 'cooperate',\n",
       " 'congruences': 'congruence',\n",
       " 'doepfner': 'doepfner',\n",
       " 'leads': 'lead',\n",
       " 'darien': 'darien',\n",
       " 'merchandisers': 'merchandiser',\n",
       " 'stocktwits': 'stocktwits',\n",
       " 'qvfd': 'qvfd',\n",
       " 'beatings': 'beating',\n",
       " 'developmentscerner': 'developmentscerner',\n",
       " 'gasi': 'gasi',\n",
       " 'standardise': 'standardise',\n",
       " 'cabgy': 'cabgy',\n",
       " 'prescribe': 'prescribe',\n",
       " 'diluting': 'dilute',\n",
       " 'kotagal': 'kotagal',\n",
       " 'picksmagellan': 'picksmagellan',\n",
       " 'perspica': 'perspica',\n",
       " 'garena': 'garena',\n",
       " 'nowthe': 'nowthe',\n",
       " 'pasquale': 'pasquale',\n",
       " 'conclusionsit': 'conclusionsit',\n",
       " 'redact': 'redact',\n",
       " 'headlinesthis': 'headlinesthis',\n",
       " 'relaunch': 'relaunch',\n",
       " 'irreparable': 'irreparable',\n",
       " 'telefonica': 'telefonica',\n",
       " 'uttering': 'utter',\n",
       " 'segoma': 'segoma',\n",
       " 'updatenextera': 'updatenextera',\n",
       " 'coalition': 'coalition',\n",
       " 'aradigm': 'aradigm',\n",
       " 'egain': 'egain',\n",
       " 'getsocial': 'getsocial',\n",
       " 'transformed': 'transformed',\n",
       " 'portland': 'portland',\n",
       " 'makarova': 'makarova',\n",
       " 'hackberry': 'hackberry',\n",
       " 'tessera': 'tessera',\n",
       " 'edmonton': 'edmonton',\n",
       " 'debated': 'debate',\n",
       " 'su': 'su',\n",
       " 'remicade': 'remicade',\n",
       " 'misinterpreted': 'misinterpret',\n",
       " 'releasesvisa': 'releasesvisa',\n",
       " 'shelves': 'shelf',\n",
       " 'littoral': 'littoral',\n",
       " 'beloved': 'beloved',\n",
       " 'hadas': 'hadas',\n",
       " 'reauthorize': 'reauthorize',\n",
       " 'dragan': 'dragan',\n",
       " 'oj': 'oj',\n",
       " 'storages': 'storage',\n",
       " 'busynot': 'busynot',\n",
       " 'lotto': 'lotto',\n",
       " 'waterways': 'waterway',\n",
       " 'complaint': 'complaint',\n",
       " 'molecule': 'molecule',\n",
       " 'downers': 'downer',\n",
       " 'orbisresearch': 'orbisresearch',\n",
       " 'derrick': 'derrick',\n",
       " 'uh': 'uh',\n",
       " 'mostchina': 'mostchina',\n",
       " 'conducts': 'conduct',\n",
       " 'comprehensible': 'comprehensible',\n",
       " 'gays': 'gay',\n",
       " 'vezel': 'vezel',\n",
       " 'communicate': 'communicate',\n",
       " 'beauchamp': 'beauchamp',\n",
       " 'wv': 'wv',\n",
       " 'trco': 'trco',\n",
       " 'attachment': 'attachment',\n",
       " 'cobble': 'cobble',\n",
       " 'hansen': 'hansen',\n",
       " 'akam': 'akam',\n",
       " 'implausible': 'implausible',\n",
       " 'ofthe': 'ofthe',\n",
       " 'greet': 'greet',\n",
       " 'ebtida': 'ebtida',\n",
       " 'precast': 'precast',\n",
       " 'hieroglyph': 'hieroglyph',\n",
       " 'dex': 'dex',\n",
       " 'croslite': 'croslite',\n",
       " 'stashed': 'stash',\n",
       " 'lankan': 'lankan',\n",
       " 'tmt': 'tmt',\n",
       " 'performanceis': 'performanceis',\n",
       " 'readable': 'readable',\n",
       " 'procurement': 'procurement',\n",
       " 'pr': 'pr',\n",
       " 'synagis': 'synagis',\n",
       " 'descartes': 'descartes',\n",
       " 'overturns': 'overturn',\n",
       " 'diroximel': 'diroximel',\n",
       " 'jammet': 'jammet',\n",
       " 'carrie': 'carrie',\n",
       " 'guidancespirit': 'guidancespirit',\n",
       " 'tsakalotos': 'tsakalotos',\n",
       " 'shifted': 'shift',\n",
       " 'thoughts': 'thought',\n",
       " 'cartel': 'cartel',\n",
       " 'wiggle': 'wiggle',\n",
       " 'narayanan': 'narayanan',\n",
       " 'credicorpis': 'credicorpis',\n",
       " 'beckerman': 'beckerman',\n",
       " 'lure': 'lure',\n",
       " 'clubhouse': 'clubhouse',\n",
       " 'gbb': 'gbb',\n",
       " 'mock': 'mock',\n",
       " 'illuminated': 'illuminate',\n",
       " 'schleswig': 'schleswig',\n",
       " 'reimbursementscalcimimetics': 'reimbursementscalcimimetics',\n",
       " 'lars': 'lars',\n",
       " 'punitive': 'punitive',\n",
       " 'iwc': 'iwc',\n",
       " 'yapple': 'yapple',\n",
       " 'belei': 'belei',\n",
       " 'mcqueeney': 'mcqueeney',\n",
       " 'implode': 'implode',\n",
       " 'boomers': 'boomer',\n",
       " 'ivascyn': 'ivascyn',\n",
       " 'xevo': 'xevo',\n",
       " 'drydock': 'drydock',\n",
       " 'sports': 'sport',\n",
       " 'factoring': 'factor',\n",
       " 'entitlement': 'entitlement',\n",
       " 'richer': 'rich',\n",
       " 'uniformly': 'uniformly',\n",
       " 'tamimi': 'tamimi',\n",
       " 'botticelliplatform': 'botticelliplatform',\n",
       " 'hiking': 'hike',\n",
       " 'guillaume': 'guillaume',\n",
       " 'benefitthis': 'benefitthis',\n",
       " 'mover': 'mover',\n",
       " 'tory': 'tory',\n",
       " 'chipmaking': 'chipmaking',\n",
       " 'auctioned': 'auction',\n",
       " 'knitted': 'knitted',\n",
       " 'thulium': 'thulium',\n",
       " 'twlo': 'twlo',\n",
       " 'competences': 'competence',\n",
       " 'tricuspid': 'tricuspid',\n",
       " 'beardgate': 'beardgate',\n",
       " 'fends': 'fends',\n",
       " 'renege': 'renege',\n",
       " 'ansari': 'ansari',\n",
       " 'veco': 'veco',\n",
       " 'signage': 'signage',\n",
       " 'consideryou': 'consideryou',\n",
       " 'binding': 'bind',\n",
       " 'movementshares': 'movementshares',\n",
       " 'choking': 'choke',\n",
       " 'zainab': 'zainab',\n",
       " 'academicians': 'academician',\n",
       " 'sonam': 'sonam',\n",
       " 'godaddy': 'godaddy',\n",
       " 'continueson': 'continueson',\n",
       " 'ltg': 'ltg',\n",
       " 'imperishable': 'imperishable',\n",
       " 'portfiolio': 'portfiolio',\n",
       " 'recessiontech': 'recessiontech',\n",
       " 'bodyguard': 'bodyguard',\n",
       " 'ryul': 'ryul',\n",
       " 'iribe': 'iribe',\n",
       " 'freshest': 'fresh',\n",
       " 'rankteledyne': 'rankteledyne',\n",
       " 'violates': 'violate',\n",
       " 'stocksbiotech': 'stocksbiotech',\n",
       " 'headfirst': 'headfirst',\n",
       " 'miniscule': 'miniscule',\n",
       " 'expressway': 'expressway',\n",
       " 'risesep': 'risesep',\n",
       " 'fallover': 'fallover',\n",
       " 'edgeif': 'edgeif',\n",
       " 'systemes': 'systemes',\n",
       " 'sceptics': 'sceptic',\n",
       " 'hammering': 'hammer',\n",
       " 'picksmosaic': 'picksmosaic',\n",
       " 'malibu': 'malibu',\n",
       " 'shaw': 'shaw',\n",
       " 'gynecology': 'gynecology',\n",
       " 'symbolically': 'symbolically',\n",
       " 'loft': 'loft',\n",
       " 'sedline': 'sedline',\n",
       " 'inc': 'inc',\n",
       " 'evgo': 'evgo',\n",
       " 'myov': 'myov',\n",
       " 'multibillion': 'multibillion',\n",
       " 'trademachine': 'trademachine',\n",
       " 'hysteria': 'hysteria',\n",
       " 'electioninvestors': 'electioninvestors',\n",
       " 'judging': 'judge',\n",
       " 'herald': 'herald',\n",
       " 'inco': 'inco',\n",
       " 'belligerency': 'belligerency',\n",
       " 'tata': 'tata',\n",
       " 'nexavar': 'nexavar',\n",
       " 'detail': 'detail',\n",
       " 'gardena': 'gardena',\n",
       " 'permits': 'permit',\n",
       " 'dfusx': 'dfusx',\n",
       " 'balmy': 'balmy',\n",
       " 'psmgn': 'psmgn',\n",
       " 'piecemeal': 'piecemeal',\n",
       " 'anger': 'anger',\n",
       " 'toca': 'toca',\n",
       " 'sameness': 'sameness',\n",
       " 'impersonation': 'impersonation',\n",
       " 'climaxing': 'climax',\n",
       " 'reorganizing': 'reorganize',\n",
       " 'ebit': 'ebit',\n",
       " 'consumable': 'consumable',\n",
       " 'picksbelow': 'picksbelow',\n",
       " 'biocon': 'biocon',\n",
       " 'sheets': 'sheet',\n",
       " 'constellium': 'constellium',\n",
       " 'austrians': 'austrians',\n",
       " 'deferral': 'deferral',\n",
       " 'taxes': 'tax',\n",
       " 'wti': 'wti',\n",
       " 'stirring': 'stir',\n",
       " 'seniority': 'seniority',\n",
       " 'lansing': 'lansing',\n",
       " 'dtg': 'dtg',\n",
       " 'disengagements': 'disengagement',\n",
       " 'systemswhile': 'systemswhile',\n",
       " 'aperture': 'aperture',\n",
       " 'logged': 'log',\n",
       " 'channelsat': 'channelsat',\n",
       " 'bludgeoned': 'bludgeon',\n",
       " 'fnko': 'fnko',\n",
       " 'pgp': 'pgp',\n",
       " 'americarevenues': 'americarevenues',\n",
       " 'sophistication': 'sophistication',\n",
       " 'aishwarya': 'aishwarya',\n",
       " 'giancola': 'giancola',\n",
       " 'picasso': 'picasso',\n",
       " 'cbdmeanwhile': 'cbdmeanwhile',\n",
       " 'sportsmen': 'sportsman',\n",
       " 'avantor': 'avantor',\n",
       " 'frackers': 'frackers',\n",
       " 'victories': 'victory',\n",
       " 'flimsy': 'flimsy',\n",
       " 'farallon': 'farallon',\n",
       " 'banker': 'banker',\n",
       " 'sanjai': 'sanjai',\n",
       " 'endgadget': 'endgadget',\n",
       " 'grillo': 'grillo',\n",
       " 'abhey': 'abhey',\n",
       " 'disparagingly': 'disparagingly',\n",
       " 'haste': 'haste',\n",
       " 'bax': 'bax',\n",
       " 'encrypts': 'encrypts',\n",
       " 'desai': 'desai',\n",
       " 'traction': 'traction',\n",
       " 'illinios': 'illinios',\n",
       " 'foxteq': 'foxteq',\n",
       " 'customerservice': 'customerservice',\n",
       " 'expropriation': 'expropriation',\n",
       " 'friedman': 'friedman',\n",
       " 'filmstruck': 'filmstruck',\n",
       " 'catheter': 'catheter',\n",
       " 'unitron': 'unitron',\n",
       " 'vinod': 'vinod',\n",
       " 'lover': 'lover',\n",
       " 'excluded': 'exclude',\n",
       " 'kinect': 'kinect',\n",
       " 'wished': 'wish',\n",
       " 'simulate': 'simulate',\n",
       " 'glpg': 'glpg',\n",
       " 'priv': 'priv',\n",
       " 'ztesoft': 'ztesoft',\n",
       " 'koin': 'koin',\n",
       " 'updatejuno': 'updatejuno',\n",
       " 'pmiswith': 'pmiswith',\n",
       " 'staunchest': 'staunch',\n",
       " 'lurkers': 'lurker',\n",
       " 'discontinued': 'discontinue',\n",
       " 'tisseel': 'tisseel',\n",
       " 'rosenstein': 'rosenstein',\n",
       " 'kathy': 'kathy',\n",
       " 'vgurpv': 'vgurpv',\n",
       " 'thasunda': 'thasunda',\n",
       " 'honest': 'honest',\n",
       " 'fundaments': 'fundament',\n",
       " 'queue': 'queue',\n",
       " 'inseego': 'inseego',\n",
       " 'aerial': 'aerial',\n",
       " 'shredded': 'shred',\n",
       " 'guestrin': 'guestrin',\n",
       " 'lianlian': 'lianlian',\n",
       " 'prepped': 'prepped',\n",
       " 'trivia': 'trivia',\n",
       " 'tftc': 'tftc',\n",
       " 'malafide': 'malafide',\n",
       " 'serial': 'serial',\n",
       " 'reread': 'reread',\n",
       " 'mfs': 'mf',\n",
       " 'unity': 'unity',\n",
       " 'shelfware': 'shelfware',\n",
       " 'gamified': 'gamified',\n",
       " 'enforcement': 'enforcement',\n",
       " 'brace': 'brace',\n",
       " 'diehard': 'diehard',\n",
       " 'tin': 'tin',\n",
       " 'glee': 'glee',\n",
       " 'celladon': 'celladon',\n",
       " 'bpce': 'bpce',\n",
       " 'arabiya': 'arabiya',\n",
       " 'mgndx': 'mgndx',\n",
       " 'triumphantly': 'triumphantly',\n",
       " 'tps': 'tps',\n",
       " 'schwan': 'schwan',\n",
       " 'pickstarget': 'pickstarget',\n",
       " 'realty': 'realty',\n",
       " 'liverail': 'liverail',\n",
       " 'hurdled': 'hurdle',\n",
       " 'nerve': 'nerve',\n",
       " 'additional': 'additional',\n",
       " 'offline': 'offline',\n",
       " 'attributedto': 'attributedto',\n",
       " 'vigodman': 'vigodman',\n",
       " 'presumes': 'presume',\n",
       " 'pzd': 'pzd',\n",
       " 'trick': 'trick',\n",
       " 'massively': 'massively',\n",
       " 'waller': 'waller',\n",
       " 'masterpass': 'masterpass',\n",
       " 'sub': 'sub',\n",
       " 'bathrooms': 'bathroom',\n",
       " 'lipstick': 'lipstick',\n",
       " 'jennifer': 'jennifer',\n",
       " 'quashed': 'quash',\n",
       " 'infinitely': 'infinitely',\n",
       " 'splrcu': 'splrcu',\n",
       " 'eternal': 'eternal',\n",
       " 'snapchats': 'snapchats',\n",
       " 'truth': 'truth',\n",
       " 'computational': 'computational',\n",
       " 'lyb': 'lyb',\n",
       " 'emera': 'emera',\n",
       " 'lzhaclpt': 'lzhaclpt',\n",
       " 'trowell': 'trowell',\n",
       " 'nitric': 'nitric',\n",
       " 'usenext': 'usenext',\n",
       " 'spaceships': 'spaceship',\n",
       " 'sleekly': 'sleekly',\n",
       " 'soundest': 'soundest',\n",
       " 'trendcoming': 'trendcoming',\n",
       " 'autoregressive': 'autoregressive',\n",
       " 'picturetoday': 'picturetoday',\n",
       " 'affirming': 'affirm',\n",
       " 'psch': 'psch',\n",
       " 'floodlights': 'floodlight',\n",
       " 'gerald': 'gerald',\n",
       " 'seadrill': 'seadrill',\n",
       " 'cruz': 'cruz',\n",
       " 'gemcutting': 'gemcutting',\n",
       " 'whispersnow': 'whispersnow',\n",
       " 'athena': 'athena',\n",
       " 'promiseamazon': 'promiseamazon',\n",
       " 'postpone': 'postpone',\n",
       " 'venerate': 'venerate',\n",
       " 'adhd': 'adhd',\n",
       " 'promoters': 'promoter',\n",
       " 'wst': 'wst',\n",
       " 'melting': 'melt',\n",
       " 'travels': 'travel',\n",
       " 'bulger': 'bulger',\n",
       " 'kazuhiro': 'kazuhiro',\n",
       " 'tbloffb': 'tbloffb',\n",
       " 'signing': 'signing',\n",
       " 'eschews': 'eschews',\n",
       " 'tabs': 'tabs',\n",
       " 'mris': 'mris',\n",
       " 'playlackluster': 'playlackluster',\n",
       " 'niti': 'niti',\n",
       " 'afinion': 'afinion',\n",
       " 'regs': 'regs',\n",
       " 'internations': 'internations',\n",
       " 'edwards': 'edward',\n",
       " 'equipping': 'equip',\n",
       " 'keyleaf': 'keyleaf',\n",
       " 'drumming': 'drum',\n",
       " 'dpw': 'dpw',\n",
       " 'legalize': 'legalize',\n",
       " 'herefurther': 'herefurther',\n",
       " 'considerak': 'considerak',\n",
       " 'imgur': 'imgur',\n",
       " 'transferring': 'transfer',\n",
       " 'lossless': 'lossless',\n",
       " 'serving': 'serve',\n",
       " 'servant': 'servant',\n",
       " 'jbl': 'jbl',\n",
       " 'reitmeister': 'reitmeister',\n",
       " 'jive': 'jive',\n",
       " 'undeveloped': 'undeveloped',\n",
       " 'ssp': 'ssp',\n",
       " 'adamantly': 'adamantly',\n",
       " 'spine': 'spine',\n",
       " 'xiabuxiabu': 'xiabuxiabu',\n",
       " 'stanphyl': 'stanphyl',\n",
       " 'scorefortive': 'scorefortive',\n",
       " 'playhelmerich': 'playhelmerich',\n",
       " 'house': 'house',\n",
       " 'aceto': 'aceto',\n",
       " 'substantiates': 'substantiate',\n",
       " 'netherlands': 'netherlands',\n",
       " 'deluxe': 'deluxe',\n",
       " 'updateone': 'updateone',\n",
       " 'huntsman': 'huntsman',\n",
       " 'deadlier': 'deadlier',\n",
       " 'arising': 'arise',\n",
       " 'multidimensional': 'multidimensional',\n",
       " 'vilify': 'vilify',\n",
       " 'exasperation': 'exasperation',\n",
       " 'curiositystream': 'curiositystream',\n",
       " 'prize': 'prize',\n",
       " 'fbm': 'fbm',\n",
       " 'aremains': 'aremains',\n",
       " 'vqt': 'vqt',\n",
       " 'raine': 'raine',\n",
       " 'maziar': 'maziar',\n",
       " 'foe': 'foe',\n",
       " 'skittishness': 'skittishness',\n",
       " 'immature': 'immature',\n",
       " 'represent': 'represent',\n",
       " 'films': 'film',\n",
       " 'sumitomo': 'sumitomo',\n",
       " 'amman': 'amman',\n",
       " 'deleverage': 'deleverage',\n",
       " 'galahad': 'galahad',\n",
       " 'brewery': 'brewery',\n",
       " 'grebler': 'grebler',\n",
       " 'miing': 'miing',\n",
       " 'boardroom': 'boardroom',\n",
       " 'socialist': 'socialist',\n",
       " 'gpi': 'gpi',\n",
       " 'combinator': 'combinator',\n",
       " 'myxoid': 'myxoid',\n",
       " 'soliton': 'soliton',\n",
       " 'keynesians': 'keynesian',\n",
       " 'lenalidomide': 'lenalidomide',\n",
       " 'jarrett': 'jarrett',\n",
       " 'bath': 'bath',\n",
       " 'pricespy': 'pricespy',\n",
       " 'defusing': 'defuse',\n",
       " 'spcb': 'spcb',\n",
       " 'fabulous': 'fabulous',\n",
       " 'simos': 'simos',\n",
       " 'frothing': 'froth',\n",
       " 'bengrina': 'bengrina',\n",
       " 'montgomery': 'montgomery',\n",
       " 'rapes': 'rap',\n",
       " 'pictureti': 'pictureti',\n",
       " 'apvo': 'apvo',\n",
       " 'cbsn': 'cbsn',\n",
       " 'tpk': 'tpk',\n",
       " 'cinch': 'cinch',\n",
       " 'breakthroughaccording': 'breakthroughaccording',\n",
       " 'nvt': 'nvt',\n",
       " 'tilbury': 'tilbury',\n",
       " 'upqtfmdr': 'upqtfmdr',\n",
       " 'bigots': 'bigot',\n",
       " 'meted': 'meted',\n",
       " 'footnotes': 'footnote',\n",
       " 'barnier': 'barnier',\n",
       " 'bbk': 'bbk',\n",
       " 'refueler': 'refueler',\n",
       " 'gaudi': 'gaudi',\n",
       " 'cejf': 'cejf',\n",
       " 'ameliorating': 'ameliorate',\n",
       " 'gmt': 'gmt',\n",
       " 'broker': 'broker',\n",
       " 'picksequinor': 'picksequinor',\n",
       " 'photography': 'photography',\n",
       " 'certifications': 'certification',\n",
       " 'stratagraft': 'stratagraft',\n",
       " 'punctured': 'puncture',\n",
       " 'vibrating': 'vibrate',\n",
       " 'best': 'best',\n",
       " 'hakko': 'hakko',\n",
       " 'eyeverify': 'eyeverify',\n",
       " 'waveforms': 'waveforms',\n",
       " 'irresponsibly': 'irresponsibly',\n",
       " 'predominantly': 'predominantly',\n",
       " 'unforgiving': 'unforgiving',\n",
       " 'yuri': 'yuri',\n",
       " 'safeguard': 'safeguard',\n",
       " 'septembertrade': 'septembertrade',\n",
       " 'afloat': 'afloat',\n",
       " 'beasley': 'beasley',\n",
       " 'backroom': 'backroom',\n",
       " 'pickschevron': 'pickschevron',\n",
       " 'pruned': 'prune',\n",
       " 'spring': 'spring',\n",
       " 'kindleberger': 'kindleberger',\n",
       " 'dags': 'dags',\n",
       " 'dairypure': 'dairypure',\n",
       " 'cveo': 'cveo',\n",
       " 'dodgedinsurers': 'dodgedinsurers',\n",
       " 'downshifted': 'downshifted',\n",
       " 'considerlamcurrently': 'considerlamcurrently',\n",
       " 'perksboth': 'perksboth',\n",
       " 'qunar': 'qunar',\n",
       " 'malcolm': 'malcolm',\n",
       " 'lvdtabdbvdiagopb': 'lvdtabdbvdiagopb',\n",
       " 'pour': 'pour',\n",
       " 'dimartino': 'dimartino',\n",
       " 'unveil': 'unveil',\n",
       " 'golden': 'golden',\n",
       " 'cohu': 'cohu',\n",
       " 'wen': 'wen',\n",
       " 'kiehl': 'kiehl',\n",
       " 'rankone': 'rankone',\n",
       " 'lerer': 'lerer',\n",
       " 'contactors': 'contactors',\n",
       " 'reshuffle': 'reshuffle',\n",
       " 'blogpost': 'blogpost',\n",
       " 'wedlock': 'wedlock',\n",
       " 'steyer': 'steyer',\n",
       " 'sliding': 'slide',\n",
       " 'wherein': 'wherein',\n",
       " 'lihkg': 'lihkg',\n",
       " 'cascading': 'cascade',\n",
       " 'droz': 'droz',\n",
       " 'perceptive': 'perceptive',\n",
       " 'splrct': 'splrct',\n",
       " 'arne': 'arne',\n",
       " 'videocamera': 'videocamera',\n",
       " 'cherokee': 'cherokee',\n",
       " 'look': 'look',\n",
       " 'cartels': 'cartel',\n",
       " 'celestial': 'celestial',\n",
       " 'consists': 'consist',\n",
       " 'mcconnell': 'mcconnell',\n",
       " 'kalgoorlie': 'kalgoorlie',\n",
       " 'motherboards': 'motherboards',\n",
       " 'lto': 'lto',\n",
       " 'zelda': 'zelda',\n",
       " 'cdm': 'cdm',\n",
       " 'dapps': 'dapps',\n",
       " 'eightfold': 'eightfold',\n",
       " 'oligopolistic': 'oligopolistic',\n",
       " 'aaagrjea': 'aaagrjea',\n",
       " 'technologiesai': 'technologiesai',\n",
       " 'wcfjntuo': 'wcfjntuo',\n",
       " 'abroad': 'abroad',\n",
       " 'throughputs': 'throughputs',\n",
       " 'eosinophilic': 'eosinophilic',\n",
       " 'aranda': 'aranda',\n",
       " 'ruffy': 'ruffy',\n",
       " 'rutledge': 'rutledge',\n",
       " 'sanjeev': 'sanjeev',\n",
       " 'takeiron': 'takeiron',\n",
       " 'ged': 'ged',\n",
       " 'bendigo': 'bendigo',\n",
       " 'martens': 'marten',\n",
       " 'patience': 'patience',\n",
       " 'chesky': 'chesky',\n",
       " 'lutz': 'lutz',\n",
       " 'markethowever': 'markethowever',\n",
       " 'shield': 'shield',\n",
       " 'republicans': 'republican',\n",
       " 'yacking': 'yack',\n",
       " 'sai': 'sai',\n",
       " 'bent': 'bent',\n",
       " 'acompli': 'acompli',\n",
       " 'wishing': 'wish',\n",
       " 'wonders': 'wonder',\n",
       " 'eafa': 'eafa',\n",
       " 'includefacebook': 'includefacebook',\n",
       " 'uvf': 'uvf',\n",
       " 'disorder': 'disorder',\n",
       " 'mobility': 'mobility',\n",
       " 'deploy': 'deploy',\n",
       " 'linevaleant': 'linevaleant',\n",
       " 'urged': 'urge',\n",
       " 'thirties': 'thirty',\n",
       " 'cile': 'cile',\n",
       " 'redbox': 'redbox',\n",
       " 'semagacestat': 'semagacestat',\n",
       " 'coffey': 'coffey',\n",
       " 'zirin': 'zirin',\n",
       " 'ng': 'ng',\n",
       " 'audible': 'audible',\n",
       " 'hovers': 'hovers',\n",
       " 'anniversary': 'anniversary',\n",
       " 'php': 'php',\n",
       " 'herbs': 'herb',\n",
       " 'embarked': 'embark',\n",
       " 'amph': 'amph',\n",
       " 'firstsourcecurrently': 'firstsourcecurrently',\n",
       " 'dogma': 'dogma',\n",
       " 'philanthropic': 'philanthropic',\n",
       " 'benefit': 'benefit',\n",
       " 'relaunched': 'relaunched',\n",
       " 'haloti': 'haloti',\n",
       " 'stancethe': 'stancethe',\n",
       " 'eurostoxx': 'eurostoxx',\n",
       " 'cup': 'cup',\n",
       " 'raj': 'raj',\n",
       " 'texans': 'texan',\n",
       " 'rashann': 'rashann',\n",
       " 'pyruvate': 'pyruvate',\n",
       " 'venrock': 'venrock',\n",
       " 'arvan': 'arvan',\n",
       " 'dermatologists': 'dermatologists',\n",
       " 'remopro': 'remopro',\n",
       " 'text': 'text',\n",
       " 'reflationary': 'reflationary',\n",
       " 'cios': 'cio',\n",
       " 'heatedly': 'heatedly',\n",
       " 'ongoing': 'ongoing',\n",
       " 'slapping': 'slap',\n",
       " 'meter': 'meter',\n",
       " 'spearhead': 'spearhead',\n",
       " 'shantaram': 'shantaram',\n",
       " 'swlsx': 'swlsx',\n",
       " 'pricingon': 'pricingon',\n",
       " 'dpps': 'dpps',\n",
       " 'allotment': 'allotment',\n",
       " 'evaporators': 'evaporators',\n",
       " 'notchless': 'notchless',\n",
       " 'update': 'update',\n",
       " 'gembox': 'gembox',\n",
       " 'quintuple': 'quintuple',\n",
       " 'jutting': 'jut',\n",
       " 'changers': 'changer',\n",
       " 'populationastrazeneca': 'populationastrazeneca',\n",
       " 'tending': 'tend',\n",
       " 'mobl': 'mobl',\n",
       " 'deathly': 'deathly',\n",
       " 'snmp': 'snmp',\n",
       " 'cozy': 'cozy',\n",
       " 'whimpers': 'whimper',\n",
       " 'optic': 'optic',\n",
       " 'depended': 'depend',\n",
       " 'evs': 'ev',\n",
       " 'retain': 'retain',\n",
       " 'cianio': 'cianio',\n",
       " 'mrw': 'mrw',\n",
       " 'conte': 'conte',\n",
       " 'aptima': 'aptima',\n",
       " 'bullhound': 'bullhound',\n",
       " 'rummage': 'rummage',\n",
       " 'ranklockheed': 'ranklockheed',\n",
       " 'huey': 'huey',\n",
       " 'nanoparticles': 'nanoparticles',\n",
       " 'blogger': 'blogger',\n",
       " 'opportunityimagine': 'opportunityimagine',\n",
       " 'gemzar': 'gemzar',\n",
       " 'kamoto': 'kamoto',\n",
       " 'quarantining': 'quarantine',\n",
       " 'beta': 'beta',\n",
       " 'appear': 'appear',\n",
       " 'med': 'med',\n",
       " 'assemblies': 'assembly',\n",
       " 'rpms': 'rpms',\n",
       " 'flowit': 'flowit',\n",
       " 'klac': 'klac',\n",
       " 'anthony': 'anthony',\n",
       " 'matched': 'match',\n",
       " 'upsidesestee': 'upsidesestee',\n",
       " 'mfem': 'mfem',\n",
       " 'natick': 'natick',\n",
       " 'narottam': 'narottam',\n",
       " 'arthur': 'arthur',\n",
       " 'armistice': 'armistice',\n",
       " 'keytrudalynparza': 'keytrudalynparza',\n",
       " 'sedans': 'sedan',\n",
       " 'bzlfy': 'bzlfy',\n",
       " 'precertified': 'precertified',\n",
       " 'takebetter': 'takebetter',\n",
       " 'zhang': 'zhang',\n",
       " 'aluminum': 'aluminum',\n",
       " 'cw': 'cw',\n",
       " 'picks': 'pick',\n",
       " 'retail': 'retail',\n",
       " 'ptc': 'ptc',\n",
       " 'zimura': 'zimura',\n",
       " 'editortoday': 'editortoday',\n",
       " 'bioreference': 'bioreference',\n",
       " 'viavi': 'viavi',\n",
       " 'aprilapril': 'aprilapril',\n",
       " 'hp': 'hp',\n",
       " 'attracts': 'attract',\n",
       " 'pinhead': 'pinhead',\n",
       " 'hathway': 'hathway',\n",
       " 'vizion': 'vizion',\n",
       " 'biomarkers': 'biomarkers',\n",
       " 'timberlands': 'timberlands',\n",
       " 'zcash': 'zcash',\n",
       " 'mun': 'mun',\n",
       " 'denies': 'denies',\n",
       " 'pen': 'pen',\n",
       " 'linejec': 'linejec',\n",
       " 'biodiesel': 'biodiesel',\n",
       " 'iett': 'iett',\n",
       " 'ubnekba': 'ubnekba',\n",
       " 'promisevirtual': 'promisevirtual',\n",
       " 'macdonald': 'macdonald',\n",
       " 'boosts': 'boost',\n",
       " 'opens': 'open',\n",
       " 'recreations': 'recreation',\n",
       " 'plumb': 'plumb',\n",
       " 'auctioneer': 'auctioneer',\n",
       " 'awards': 'award',\n",
       " 'pancreas': 'pancreas',\n",
       " 'televising': 'televise',\n",
       " 'hailed': 'hail',\n",
       " 'marketsmith': 'marketsmith',\n",
       " 'basketful': 'basketful',\n",
       " 'akhil': 'akhil',\n",
       " 'splatoon': 'splatoon',\n",
       " 'beatbox': 'beatbox',\n",
       " 'peterson': 'peterson',\n",
       " 'comco': 'comco',\n",
       " 'dealwhile': 'dealwhile',\n",
       " 'buckhead': 'buckhead',\n",
       " 'yrmaxh': 'yrmaxh',\n",
       " 'deprioritized': 'deprioritized',\n",
       " 'servicescitigroup': 'servicescitigroup',\n",
       " 'rdm': 'rdm',\n",
       " 'laurentiis': 'laurentiis',\n",
       " 'yeti': 'yeti',\n",
       " 'levinsohn': 'levinsohn',\n",
       " 'moorestown': 'moorestown',\n",
       " 'piercing': 'pierce',\n",
       " 'sensitive': 'sensitive',\n",
       " 'eleks': 'eleks',\n",
       " 'newest': 'new',\n",
       " 'millicom': 'millicom',\n",
       " 'fayne': 'fayne',\n",
       " 'times': 'time',\n",
       " 'pinnacle': 'pinnacle',\n",
       " 'roseville': 'roseville',\n",
       " 'conoccophillips': 'conoccophillips',\n",
       " 'indicated': 'indicate',\n",
       " 'support': 'support',\n",
       " 'rankcms': 'rankcms',\n",
       " 'excessively': 'excessively',\n",
       " 'yung': 'yung',\n",
       " 'gorge': 'gorge',\n",
       " 'handset': 'handset',\n",
       " 'est': 'est',\n",
       " 'lures': 'lure',\n",
       " 'yong': 'yong',\n",
       " 'berrisch': 'berrisch',\n",
       " 'furniture': 'furniture',\n",
       " 'driven': 'drive',\n",
       " 'memes': 'memes',\n",
       " 'twitterthe': 'twitterthe',\n",
       " 'eta': 'eta',\n",
       " 'reserves': 'reserve',\n",
       " 'snuggly': 'snuggly',\n",
       " 'underpaid': 'underpaid',\n",
       " 'linealexion': 'linealexion',\n",
       " 'imgcaptiontext': 'imgcaptiontext',\n",
       " 'vows': 'vow',\n",
       " 'wracking': 'wrack',\n",
       " 'enigmatic': 'enigmatic',\n",
       " 'gynecologic': 'gynecologic',\n",
       " 'turtle': 'turtle',\n",
       " 'wwbx': 'wwbx',\n",
       " 'sharma': 'sharma',\n",
       " 'bobsled': 'bobsled',\n",
       " 'businessmen': 'businessmen',\n",
       " 'musician': 'musician',\n",
       " 'gtb': 'gtb',\n",
       " 'underperform': 'underperform',\n",
       " 'remission': 'remission',\n",
       " 'trumaine': 'trumaine',\n",
       " 'mcenroe': 'mcenroe',\n",
       " 'ratiogoogle': 'ratiogoogle',\n",
       " 'vestberg': 'vestberg',\n",
       " 'kani': 'kani',\n",
       " 'considerhewlett': 'considerhewlett',\n",
       " 'deliberately': 'deliberately',\n",
       " 'anthropologie': 'anthropologie',\n",
       " 'paez': 'paez',\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_token_set = set(\" \".join(test_news_df['content']).split(\" \"))\n",
    "unique_token_tagged = pos_tag(unique_token_set, tagset='universal')\n",
    "tag_abbrev_dict = {\"NOUN\": \"n\",\n",
    "                   \"VERB\": \"v\",\n",
    "                   \"ADJ\": \"a\",\n",
    "                   \"ADV\": \"r\"}\n",
    "\n",
    "unique_token_tagged_abbrev = [(token, tag_abbrev_dict[pos_tag]) for (token, pos_tag) in unique_token_tagged if pos_tag in tag_abbrev_dict.keys()]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens_dict = {token: lemmatizer.lemmatize(token, pos=pos_tag) for (token, pos_tag) in unique_token_tagged_abbrev}\n",
    "lemmatized_tokens_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_content(tokens, token_dict):\n",
    "    lemmatized_tokens = [lemmatized_tokens_dict[token] if token in token_dict.keys() else token for token in tokens ]\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news_df['content'] = test_news_df['tokens'].apply(lemmatize_content, token_dict=lemmatized_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12197    qualcomm inc nasdaq qcom large mobile chipset ...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_news_df[test_news_df['content'].str.contains(\"qualcommyear\")]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "m2 = vectorizer.fit_transform(test_news_df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa aa', 'aa aaa', 'aa add', ..., 'zzamoi eamazmfpaydqapaojbet',\n",
       "       'zzsixxfnfuhcdofbu style', 'zzz lhmpphaewuk'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>release_date</th>\n",
       "      <th>provider</th>\n",
       "      <th>url</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price_higher</th>\n",
       "      <th>words_amount</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lexical_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>270719</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Set To Beat Q1 Earnings Estimates  Tech ...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>technology giant apple nasdaq aapl set release...</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Zacks Investment Research</td>\n",
       "      <td>https://www.investing.com/analysis/apple-set-t...</td>\n",
       "      <td>200501897</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>[technology, giant, apple, nasdaq, aapl, set, ...</td>\n",
       "      <td>0.598101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>270720</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Tech Daily  Intel Results  Netflix Surge  Appl...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>top story digest intel nyse earnings netflix n...</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Zacks Investment Research</td>\n",
       "      <td>https://www.investing.com/analysis/tech-daily-...</td>\n",
       "      <td>200501955</td>\n",
       "      <td>0</td>\n",
       "      <td>2098</td>\n",
       "      <td>[top, stories, digest, intel, nyse, earnings, ...</td>\n",
       "      <td>0.665410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>270722</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7 Monster Stock Market Predictions For The Wee...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>p spy week pack economic data earnings extent ...</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Michael Kramer</td>\n",
       "      <td>https://www.investing.com/analysis/7-monster-s...</td>\n",
       "      <td>200501656</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>[p, spy, week, packed, economic, data, earning...</td>\n",
       "      <td>0.648148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>270723</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Earnings Preview  5G Launch  Expanding S...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>report result tuesday jan revenue expectation ...</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Haris Anwar/Investing.com</td>\n",
       "      <td>https://www.investing.com/analysis/apple-earni...</td>\n",
       "      <td>200501661</td>\n",
       "      <td>0</td>\n",
       "      <td>647</td>\n",
       "      <td>[reports, results, tuesday, jan, revenue, expe...</td>\n",
       "      <td>0.711599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>270725</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Buy Surging Apple   Microsoft Stock Before Qua...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>today episode full court finance zacks dive ev...</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>Zacks Investment Research</td>\n",
       "      <td>https://www.investing.com/analysis/buy-surging...</td>\n",
       "      <td>200501950</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>[today, episode, full, court, finance, zacks, ...</td>\n",
       "      <td>0.793296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608</th>\n",
       "      <td>290911</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Chart Review  Apple Breaks Out</td>\n",
       "      <td>opinion</td>\n",
       "      <td>recovery post earnings dip july officially com...</td>\n",
       "      <td>2012-08-07</td>\n",
       "      <td>Dr. Duru</td>\n",
       "      <td>https://www.investing.com/analysis/chart-revie...</td>\n",
       "      <td>132227</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>[recovery, post, earnings, dip, july, official...</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17610</th>\n",
       "      <td>290913</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>VIX Is Under 14   Now What</td>\n",
       "      <td>opinion</td>\n",
       "      <td>ok trader buddy bet something think would happ...</td>\n",
       "      <td>2012-08-14</td>\n",
       "      <td>ETF Prophet</td>\n",
       "      <td>https://www.investing.com/analysis/vix-is-unde...</td>\n",
       "      <td>132828</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>[ok, trader, buddies, bet, something, think, w...</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17611</th>\n",
       "      <td>290914</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Largest USA Tech Companies Earnings Plunge  Bu...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>quarterly net incomethe large usa tech company...</td>\n",
       "      <td>2012-08-14</td>\n",
       "      <td>David Dyer</td>\n",
       "      <td>https://www.investing.com/analysis/largest-usa...</td>\n",
       "      <td>132868</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>[quarterly, net, incomethe, largest, usa, tech...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17612</th>\n",
       "      <td>290915</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Why Bearish Short Term  Still Buying Stocks Lo...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>understand bearish market rest year yet contin...</td>\n",
       "      <td>2012-08-15</td>\n",
       "      <td>Charles Biderman</td>\n",
       "      <td>https://www.investing.com/analysis/why-bearish...</td>\n",
       "      <td>133009</td>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "      <td>[understand, bearish, markets, rest, year, yet...</td>\n",
       "      <td>0.648208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17614</th>\n",
       "      <td>290917</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Market Bait And Switch</td>\n",
       "      <td>opinion</td>\n",
       "      <td>sound go hear soon btfd crowd far condition bt...</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>BB Finance Blog</td>\n",
       "      <td>https://www.investing.com/analysis/market-bait...</td>\n",
       "      <td>130603</td>\n",
       "      <td>0</td>\n",
       "      <td>589</td>\n",
       "      <td>[sound, going, hear, soon, btfd, crowd, far, c...</td>\n",
       "      <td>0.763485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8095 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id ticker                                              title  \\\n",
       "69     270719   AAPL  Apple Set To Beat Q1 Earnings Estimates  Tech ...   \n",
       "70     270720   AAPL  Tech Daily  Intel Results  Netflix Surge  Appl...   \n",
       "71     270722   AAPL  7 Monster Stock Market Predictions For The Wee...   \n",
       "72     270723   AAPL  Apple Earnings Preview  5G Launch  Expanding S...   \n",
       "73     270725   AAPL  Buy Surging Apple   Microsoft Stock Before Qua...   \n",
       "...       ...    ...                                                ...   \n",
       "17608  290911   AAPL                     Chart Review  Apple Breaks Out   \n",
       "17610  290913   AAPL                        VIX Is Under 14   Now What    \n",
       "17611  290914   AAPL  Largest USA Tech Companies Earnings Plunge  Bu...   \n",
       "17612  290915   AAPL  Why Bearish Short Term  Still Buying Stocks Lo...   \n",
       "17614  290917   AAPL                             Market Bait And Switch   \n",
       "\n",
       "      category                                            content  \\\n",
       "69     opinion  technology giant apple nasdaq aapl set release...   \n",
       "70     opinion  top story digest intel nyse earnings netflix n...   \n",
       "71     opinion  p spy week pack economic data earnings extent ...   \n",
       "72     opinion  report result tuesday jan revenue expectation ...   \n",
       "73     opinion  today episode full court finance zacks dive ev...   \n",
       "...        ...                                                ...   \n",
       "17608  opinion  recovery post earnings dip july officially com...   \n",
       "17610  opinion  ok trader buddy bet something think would happ...   \n",
       "17611  opinion  quarterly net incomethe large usa tech company...   \n",
       "17612  opinion  understand bearish market rest year yet contin...   \n",
       "17614  opinion  sound go hear soon btfd crowd far condition bt...   \n",
       "\n",
       "      release_date                   provider  \\\n",
       "69      2020-01-27  Zacks Investment Research   \n",
       "70      2020-01-27  Zacks Investment Research   \n",
       "71      2020-01-27             Michael Kramer   \n",
       "72      2020-01-27  Haris Anwar/Investing.com   \n",
       "73      2020-01-27  Zacks Investment Research   \n",
       "...            ...                        ...   \n",
       "17608   2012-08-07                   Dr. Duru   \n",
       "17610   2012-08-14                ETF Prophet   \n",
       "17611   2012-08-14                 David Dyer   \n",
       "17612   2012-08-15           Charles Biderman   \n",
       "17614   2012-07-24            BB Finance Blog   \n",
       "\n",
       "                                                     url  article_id  \\\n",
       "69     https://www.investing.com/analysis/apple-set-t...   200501897   \n",
       "70     https://www.investing.com/analysis/tech-daily-...   200501955   \n",
       "71     https://www.investing.com/analysis/7-monster-s...   200501656   \n",
       "72     https://www.investing.com/analysis/apple-earni...   200501661   \n",
       "73     https://www.investing.com/analysis/buy-surging...   200501950   \n",
       "...                                                  ...         ...   \n",
       "17608  https://www.investing.com/analysis/chart-revie...      132227   \n",
       "17610  https://www.investing.com/analysis/vix-is-unde...      132828   \n",
       "17611  https://www.investing.com/analysis/largest-usa...      132868   \n",
       "17612  https://www.investing.com/analysis/why-bearish...      133009   \n",
       "17614  https://www.investing.com/analysis/market-bait...      130603   \n",
       "\n",
       "       price_higher  words_amount  \\\n",
       "69                0           709   \n",
       "70                0          2098   \n",
       "71                0           508   \n",
       "72                0           647   \n",
       "73                0           361   \n",
       "...             ...           ...   \n",
       "17608             0           147   \n",
       "17610             0           263   \n",
       "17611             0           619   \n",
       "17612             0           648   \n",
       "17614             0           589   \n",
       "\n",
       "                                                  tokens  lexical_div  \n",
       "69     [technology, giant, apple, nasdaq, aapl, set, ...     0.598101  \n",
       "70     [top, stories, digest, intel, nyse, earnings, ...     0.665410  \n",
       "71     [p, spy, week, packed, economic, data, earning...     0.648148  \n",
       "72     [reports, results, tuesday, jan, revenue, expe...     0.711599  \n",
       "73     [today, episode, full, court, finance, zacks, ...     0.793296  \n",
       "...                                                  ...          ...  \n",
       "17608  [recovery, post, earnings, dip, july, official...     0.855263  \n",
       "17610  [ok, trader, buddies, bet, something, think, w...     0.859375  \n",
       "17611  [quarterly, net, incomethe, largest, usa, tech...     0.500000  \n",
       "17612  [understand, bearish, markets, rest, year, yet...     0.648208  \n",
       "17614  [sound, going, hear, soon, btfd, crowd, far, c...     0.763485  \n",
       "\n",
       "[8095 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_news_df[test_news_df['price_higher']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chuck',\n",
       " 'mikolajczak',\n",
       " 'new',\n",
       " 'york',\n",
       " 'reuters',\n",
       " 'u',\n",
       " 'stocks',\n",
       " 'suffered',\n",
       " 'worst',\n",
       " 'day',\n",
       " 'three',\n",
       " 'months',\n",
       " 'monday',\n",
       " 'china',\n",
       " 'extended',\n",
       " 'lunar',\n",
       " 'new',\n",
       " 'year',\n",
       " 'holiday',\n",
       " 'due',\n",
       " 'virus',\n",
       " 'outbreak',\n",
       " 'fueling',\n",
       " 'worries',\n",
       " 'economic',\n",
       " 'impact',\n",
       " 'containment',\n",
       " 'efforts',\n",
       " 'world',\n",
       " 'second',\n",
       " 'largest',\n",
       " 'economy',\n",
       " 'benchmark',\n",
       " 'p',\n",
       " 'suffered',\n",
       " 'worst',\n",
       " 'weekly',\n",
       " 'performance',\n",
       " 'since',\n",
       " 'september',\n",
       " 'last',\n",
       " 'week',\n",
       " 'china',\n",
       " 'locked',\n",
       " 'several',\n",
       " 'cities',\n",
       " 'curbed',\n",
       " 'travel',\n",
       " 'reminding',\n",
       " 'investors',\n",
       " 'deadly',\n",
       " 'sars',\n",
       " 'virus',\n",
       " 'killed',\n",
       " 'nearly',\n",
       " 'people',\n",
       " 'cost',\n",
       " 'global',\n",
       " 'economy',\n",
       " 'billions',\n",
       " 'still',\n",
       " 'investors',\n",
       " 'viewed',\n",
       " 'long',\n",
       " 'term',\n",
       " 'economic',\n",
       " 'impact',\n",
       " 'unlikely',\n",
       " 'given',\n",
       " 'past',\n",
       " 'experiences',\n",
       " 'viral',\n",
       " 'outbreaks',\n",
       " 'whole',\n",
       " 'thing',\n",
       " 'way',\n",
       " 'overblown',\n",
       " 'said',\n",
       " 'stephen',\n",
       " 'massocca',\n",
       " 'senior',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'wedbush',\n",
       " 'securities',\n",
       " 'san',\n",
       " 'francisco',\n",
       " 'seems',\n",
       " 'chinese',\n",
       " 'much',\n",
       " 'better',\n",
       " 'job',\n",
       " 'containing',\n",
       " 'sars',\n",
       " 'sars',\n",
       " 'ultimately',\n",
       " 'lead',\n",
       " 'lead',\n",
       " 'sort',\n",
       " 'economic',\n",
       " 'catastrophe',\n",
       " 'sars',\n",
       " 'severe',\n",
       " 'acute',\n",
       " 'respiratory',\n",
       " 'syndrome',\n",
       " 'outbreak',\n",
       " 'p',\n",
       " 'rallied',\n",
       " 'start',\n",
       " 'outbreak',\n",
       " 'announcement',\n",
       " 'containment',\n",
       " 'graphic',\n",
       " 'p',\n",
       " 'rallied',\n",
       " 'sars',\n",
       " 'spread',\n",
       " 'travel',\n",
       " 'related',\n",
       " 'stocks',\n",
       " 'including',\n",
       " 'airlines',\n",
       " 'casinos',\n",
       " 'hotels',\n",
       " 'among',\n",
       " 'hardest',\n",
       " 'hit',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'shares',\n",
       " 'sectors',\n",
       " 'exposed',\n",
       " 'china',\n",
       " 'growth',\n",
       " 'including',\n",
       " 'technology',\n",
       " 'splrct',\n",
       " 'materials',\n",
       " 'splrcm',\n",
       " 'energy',\n",
       " 'spny',\n",
       " 'pressured',\n",
       " 'markets',\n",
       " 'adding',\n",
       " 'downside',\n",
       " 'pressure',\n",
       " 'sluggish',\n",
       " 'start',\n",
       " 'corporate',\n",
       " 'earnings',\n",
       " 'season',\n",
       " 'indexes',\n",
       " 'near',\n",
       " 'record',\n",
       " 'levels',\n",
       " 'earnings',\n",
       " 'expected',\n",
       " 'show',\n",
       " 'decline',\n",
       " 'fourth',\n",
       " 'quarter',\n",
       " 'according',\n",
       " 'refinitiv',\n",
       " 'data',\n",
       " 'companies',\n",
       " 'reported',\n",
       " 'though',\n",
       " 'monday',\n",
       " 'morning',\n",
       " 'topped',\n",
       " 'expectations',\n",
       " 'rate',\n",
       " 'past',\n",
       " 'four',\n",
       " 'quarters',\n",
       " 'dow',\n",
       " 'jones',\n",
       " 'industrial',\n",
       " 'average',\n",
       " 'dji',\n",
       " 'fell',\n",
       " 'points',\n",
       " 'p',\n",
       " 'spx',\n",
       " 'lost',\n",
       " 'points',\n",
       " 'nasdaq',\n",
       " 'composite',\n",
       " 'ixic',\n",
       " 'dropped',\n",
       " 'points',\n",
       " 'dow',\n",
       " 'p',\n",
       " 'biggest',\n",
       " 'one',\n",
       " 'day',\n",
       " 'percentage',\n",
       " 'drop',\n",
       " 'since',\n",
       " 'oct',\n",
       " 'nasdaq',\n",
       " 'fall',\n",
       " 'largest',\n",
       " 'since',\n",
       " 'aug',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'fear',\n",
       " 'gauge',\n",
       " 'cboe',\n",
       " 'volatility',\n",
       " 'index',\n",
       " 'vix',\n",
       " 'reached',\n",
       " 'highest',\n",
       " 'since',\n",
       " 'oct',\n",
       " 'technology',\n",
       " 'internet',\n",
       " 'heavyweights',\n",
       " 'powered',\n",
       " 'recent',\n",
       " 'rally',\n",
       " 'including',\n",
       " 'apple',\n",
       " 'inc',\n",
       " 'aapl',\n",
       " 'microsoft',\n",
       " 'corp',\n",
       " 'msft',\n",
       " 'alphabet',\n",
       " 'inc',\n",
       " 'googl',\n",
       " 'amazon',\n",
       " 'com',\n",
       " 'inc',\n",
       " 'amzn',\n",
       " 'account',\n",
       " 'p',\n",
       " 'weighting',\n",
       " 'lost',\n",
       " 'least',\n",
       " 'wynn',\n",
       " 'resorts',\n",
       " 'ltd',\n",
       " 'wynn',\n",
       " 'melco',\n",
       " 'resorts',\n",
       " 'entertainment',\n",
       " 'ltd',\n",
       " 'mlco',\n",
       " 'las',\n",
       " 'vegas',\n",
       " 'sands',\n",
       " 'corp',\n",
       " 'n',\n",
       " 'lvs',\n",
       " 'large',\n",
       " 'operations',\n",
       " 'china',\n",
       " 'plunged',\n",
       " 'least',\n",
       " 'nyse',\n",
       " 'arca',\n",
       " 'airline',\n",
       " 'index',\n",
       " 'xal',\n",
       " 'dropped',\n",
       " 'yum',\n",
       " 'china',\n",
       " 'holdings',\n",
       " 'inc',\n",
       " 'n',\n",
       " 'yumc',\n",
       " 'tumbled',\n",
       " 'company',\n",
       " 'said',\n",
       " 'temporarily',\n",
       " 'closed',\n",
       " 'kfc',\n",
       " 'pizza',\n",
       " 'hut',\n",
       " 'stores',\n",
       " 'wuhan',\n",
       " 'epicenter',\n",
       " 'outbreak',\n",
       " 'rush',\n",
       " 'safe',\n",
       " 'assets',\n",
       " 'sank',\n",
       " 'u',\n",
       " 'treasury',\n",
       " 'yields',\n",
       " 'benchmark',\n",
       " 'year',\n",
       " 'note',\n",
       " 'rr',\n",
       " 'falling',\n",
       " 'low',\n",
       " 'lowest',\n",
       " 'since',\n",
       " 'oct',\n",
       " 'yield',\n",
       " 'curve',\n",
       " 'two',\n",
       " 'year',\n",
       " 'rr',\n",
       " 'year',\n",
       " 'rr',\n",
       " 'inverting',\n",
       " 'first',\n",
       " 'time',\n",
       " 'since',\n",
       " 'dec',\n",
       " 'putting',\n",
       " 'pressure',\n",
       " 'lenders',\n",
       " 'p',\n",
       " 'banks',\n",
       " 'index',\n",
       " 'p',\n",
       " 'energy',\n",
       " 'index',\n",
       " 'spny',\n",
       " 'dropped',\n",
       " 'crude',\n",
       " 'prices',\n",
       " 'settled',\n",
       " 'fears',\n",
       " 'outbreak',\n",
       " 'would',\n",
       " 'dent',\n",
       " 'demand',\n",
       " 'fourth',\n",
       " 'quarter',\n",
       " 'earnings',\n",
       " 'kick',\n",
       " 'high',\n",
       " 'gear',\n",
       " 'week',\n",
       " 'p',\n",
       " 'companies',\n",
       " 'including',\n",
       " 'apple',\n",
       " 'microsoft',\n",
       " 'corp',\n",
       " 'boeing',\n",
       " 'co',\n",
       " 'n',\n",
       " 'ba',\n",
       " 'reporting',\n",
       " 'declining',\n",
       " 'issues',\n",
       " 'outnumbered',\n",
       " 'advancing',\n",
       " 'ones',\n",
       " 'nyse',\n",
       " 'ratio',\n",
       " 'nasdaq',\n",
       " 'ratio',\n",
       " 'favored',\n",
       " 'decliners',\n",
       " 'p',\n",
       " 'posted',\n",
       " 'new',\n",
       " 'week',\n",
       " 'highs',\n",
       " 'new',\n",
       " 'lows',\n",
       " 'nasdaq',\n",
       " 'composite',\n",
       " 'recorded',\n",
       " 'new',\n",
       " 'highs',\n",
       " 'new',\n",
       " 'lows',\n",
       " 'billion',\n",
       " 'shares',\n",
       " 'changed',\n",
       " 'hands',\n",
       " 'u',\n",
       " 'exchanges',\n",
       " 'compared',\n",
       " 'billion',\n",
       " 'daily',\n",
       " 'average',\n",
       " 'last',\n",
       " 'sessions']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_news_df['tokens'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>release_date</th>\n",
       "      <th>provider</th>\n",
       "      <th>url</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price_higher</th>\n",
       "      <th>words_amount</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lexical_div</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270698</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>JPMorgan cautious ahead of Apple earnings</td>\n",
       "      <td>news</td>\n",
       "      <td>jpmorgan lift apple aapl target ahead tomorrow...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pnjv8</td>\n",
       "      <td>2068762</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>[jpmorgan, lifts, apple, aapl, target, ahead, ...</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270699</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>FAANG s Fall  but Get Some Wall Street Love</td>\n",
       "      <td>news</td>\n",
       "      <td>kim khan invest com faang stock predictably st...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>2068765</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>[kim, khan, investing, com, faang, stocks, pre...</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270700</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Wall Street tumbles as virus fuels economic worry</td>\n",
       "      <td>news</td>\n",
       "      <td>chuck mikolajczak new york reuters u stock suf...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>2068311</td>\n",
       "      <td>1</td>\n",
       "      <td>866</td>\n",
       "      <td>[chuck, mikolajczak, new, york, reuters, u, st...</td>\n",
       "      <td>0.717224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270701</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Earnings Watch  Apple and AMD to take earnings...</td>\n",
       "      <td>news</td>\n",
       "      <td>two best perform tech stock set report result ...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>https://invst.ly/pnlbs</td>\n",
       "      <td>2068906</td>\n",
       "      <td>1</td>\n",
       "      <td>1306</td>\n",
       "      <td>[two, best, performing, tech, stocks, set, rep...</td>\n",
       "      <td>0.684601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270702</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Day Ahead  Top 3 Things to Watch for Jan 28</td>\n",
       "      <td>news</td>\n",
       "      <td>yasin ebrahim kim khan apple ready earnings in...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>Investing.com</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>2068907</td>\n",
       "      <td>1</td>\n",
       "      <td>628</td>\n",
       "      <td>[yasin, ebrahim, kim, khan, apple, readies, ea...</td>\n",
       "      <td>0.702532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17619</th>\n",
       "      <td>290924</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Waiting For Direction On The Markets</td>\n",
       "      <td>opinion</td>\n",
       "      <td>stock market difficult one trader investor ali...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>Cam Hui</td>\n",
       "      <td>https://www.investing.com/analysis/waiting-for...</td>\n",
       "      <td>129680</td>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>[stock, market, difficult, one, traders, inves...</td>\n",
       "      <td>0.659432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17620</th>\n",
       "      <td>290925</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Mid Year Update  U S  And Canadian Stock Marke...</td>\n",
       "      <td>opinion</td>\n",
       "      <td>tsx index lead canadian stock outperform p ind...</td>\n",
       "      <td>2012-07-19</td>\n",
       "      <td>Baskin Financial Blog</td>\n",
       "      <td>https://www.investing.com/analysis/mid-year-up...</td>\n",
       "      <td>130056</td>\n",
       "      <td>1</td>\n",
       "      <td>1601</td>\n",
       "      <td>[tsx, index, leading, canadian, stocks, outper...</td>\n",
       "      <td>0.557616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>290926</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Summer Heat Scorches Europe And U S</td>\n",
       "      <td>opinion</td>\n",
       "      <td>europe flare summer heat continue summer heat ...</td>\n",
       "      <td>2012-07-23</td>\n",
       "      <td>John Nyaradi</td>\n",
       "      <td>https://www.investing.com/analysis/summer-heat...</td>\n",
       "      <td>130439</td>\n",
       "      <td>1</td>\n",
       "      <td>647</td>\n",
       "      <td>[europe, flares, summer, heat, continues, summ...</td>\n",
       "      <td>0.705521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17622</th>\n",
       "      <td>290927</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Earnings Preview  Quarterly Dip On Deck</td>\n",
       "      <td>opinion</td>\n",
       "      <td>last quarter apple aapl report best quarter co...</td>\n",
       "      <td>2012-07-23</td>\n",
       "      <td>David Dyer</td>\n",
       "      <td>https://www.investing.com/analysis/apple-earni...</td>\n",
       "      <td>130458</td>\n",
       "      <td>1</td>\n",
       "      <td>877</td>\n",
       "      <td>[last, quarter, apple, aapl, reported, best, q...</td>\n",
       "      <td>0.482667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17623</th>\n",
       "      <td>290928</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Trade Apple After Earnings</td>\n",
       "      <td>opinion</td>\n",
       "      <td>may look like spider web mishmash trendlines m...</td>\n",
       "      <td>2012-07-23</td>\n",
       "      <td>Abigail Doolittle</td>\n",
       "      <td>https://www.investing.com/analysis/trade-apple...</td>\n",
       "      <td>130440</td>\n",
       "      <td>1</td>\n",
       "      <td>542</td>\n",
       "      <td>[may, look, like, spider, web, mishmash, trend...</td>\n",
       "      <td>0.650862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17624 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id ticker                                              title  \\\n",
       "0      270698   AAPL          JPMorgan cautious ahead of Apple earnings   \n",
       "1      270699   AAPL        FAANG s Fall  but Get Some Wall Street Love   \n",
       "2      270700   AAPL  Wall Street tumbles as virus fuels economic worry   \n",
       "3      270701   AAPL  Earnings Watch  Apple and AMD to take earnings...   \n",
       "4      270702   AAPL        Day Ahead  Top 3 Things to Watch for Jan 28   \n",
       "...       ...    ...                                                ...   \n",
       "17619  290924   AAPL               Waiting For Direction On The Markets   \n",
       "17620  290925   AAPL  Mid Year Update  U S  And Canadian Stock Marke...   \n",
       "17621  290926   AAPL               Summer Heat Scorches Europe And U S    \n",
       "17622  290927   AAPL     Apple Earnings Preview  Quarterly Dip On Deck    \n",
       "17623  290928   AAPL                         Trade Apple After Earnings   \n",
       "\n",
       "      category                                            content  \\\n",
       "0         news  jpmorgan lift apple aapl target ahead tomorrow...   \n",
       "1         news  kim khan invest com faang stock predictably st...   \n",
       "2         news  chuck mikolajczak new york reuters u stock suf...   \n",
       "3         news  two best perform tech stock set report result ...   \n",
       "4         news  yasin ebrahim kim khan apple ready earnings in...   \n",
       "...        ...                                                ...   \n",
       "17619  opinion  stock market difficult one trader investor ali...   \n",
       "17620  opinion  tsx index lead canadian stock outperform p ind...   \n",
       "17621  opinion  europe flare summer heat continue summer heat ...   \n",
       "17622  opinion  last quarter apple aapl report best quarter co...   \n",
       "17623  opinion  may look like spider web mishmash trendlines m...   \n",
       "\n",
       "      release_date               provider  \\\n",
       "0       2020-01-28          Seeking Alpha   \n",
       "1       2020-01-28          Investing.com   \n",
       "2       2020-01-28                Reuters   \n",
       "3       2020-01-28            MarketWatch   \n",
       "4       2020-01-28          Investing.com   \n",
       "...            ...                    ...   \n",
       "17619   2012-07-16                Cam Hui   \n",
       "17620   2012-07-19  Baskin Financial Blog   \n",
       "17621   2012-07-23           John Nyaradi   \n",
       "17622   2012-07-23             David Dyer   \n",
       "17623   2012-07-23      Abigail Doolittle   \n",
       "\n",
       "                                                     url  article_id  \\\n",
       "0                                 https://invst.ly/pnjv8     2068762   \n",
       "1      https://www.investing.com/news/stock-market-ne...     2068765   \n",
       "2      https://www.investing.com/news/stock-market-ne...     2068311   \n",
       "3                                 https://invst.ly/pnlbs     2068906   \n",
       "4      https://www.investing.com/news/stock-market-ne...     2068907   \n",
       "...                                                  ...         ...   \n",
       "17619  https://www.investing.com/analysis/waiting-for...      129680   \n",
       "17620  https://www.investing.com/analysis/mid-year-up...      130056   \n",
       "17621  https://www.investing.com/analysis/summer-heat...      130439   \n",
       "17622  https://www.investing.com/analysis/apple-earni...      130458   \n",
       "17623  https://www.investing.com/analysis/trade-apple...      130440   \n",
       "\n",
       "       price_higher  words_amount  \\\n",
       "0                 1           102   \n",
       "1                 1           290   \n",
       "2                 1           866   \n",
       "3                 1          1306   \n",
       "4                 1           628   \n",
       "...             ...           ...   \n",
       "17619             1          1287   \n",
       "17620             1          1601   \n",
       "17621             1           647   \n",
       "17622             1           877   \n",
       "17623             1           542   \n",
       "\n",
       "                                                  tokens  lexical_div  \n",
       "0      [jpmorgan, lifts, apple, aapl, target, ahead, ...     0.857143  \n",
       "1      [kim, khan, investing, com, faang, stocks, pre...     0.729167  \n",
       "2      [chuck, mikolajczak, new, york, reuters, u, st...     0.717224  \n",
       "3      [two, best, performing, tech, stocks, set, rep...     0.684601  \n",
       "4      [yasin, ebrahim, kim, khan, apple, readies, ea...     0.702532  \n",
       "...                                                  ...          ...  \n",
       "17619  [stock, market, difficult, one, traders, inves...     0.659432  \n",
       "17620  [tsx, index, leading, canadian, stocks, outper...     0.557616  \n",
       "17621  [europe, flares, summer, heat, continues, summ...     0.705521  \n",
       "17622  [last, quarter, apple, aapl, reported, best, q...     0.482667  \n",
       "17623  [may, look, like, spider, web, mishmash, trend...     0.650862  \n",
       "\n",
       "[17624 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Train word2vec model\n",
    "word2vec_model = Word2Vec(sentences=test_news_df['tokens'], vector_size=500, window=5, min_count=1, sg=1)\n",
    "\n",
    "def document_vector(tokens):\n",
    "    tokens = [token for token in tokens if token in word2vec_model.wv]\n",
    "    \n",
    "    if len(tokens) > 0:\n",
    "        return np.mean(word2vec_model.wv[tokens], axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "test_news_df['doc_vector'] = test_news_df['tokens'].apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(test_news_df['doc_vector'])\n",
    "y = test_news_df['price_higher']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Labels:\n",
      "7188     1\n",
      "12094    1\n",
      "101      1\n",
      "1039     1\n",
      "313      1\n",
      "        ..\n",
      "2236     1\n",
      "15970    1\n",
      "12279    0\n",
      "4230     0\n",
      "1747     0\n",
      "Name: price_higher, Length: 3525, dtype: int64\n",
      "\n",
      "Predicted Labels:\n",
      "[1 1 0 ... 0 0 1]\n",
      "Gaussian Naive Bayes Accuracy: 0.5253900709219859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.62      0.55      1612\n",
      "           1       0.58      0.44      0.50      1913\n",
      "\n",
      "    accuracy                           0.53      3525\n",
      "   macro avg       0.53      0.53      0.52      3525\n",
      "weighted avg       0.54      0.53      0.52      3525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "gnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "gnb_predictions = gnb_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Actual Labels:\")\n",
    "print(y_test)\n",
    "\n",
    "print(\"\\nPredicted Labels:\")\n",
    "print(gnb_predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, gnb_predictions)\n",
    "print(f\"Gaussian Naive Bayes Accuracy: {accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual Labels:\n",
      "7188     1\n",
      "12094    1\n",
      "101      1\n",
      "1039     1\n",
      "313      1\n",
      "        ..\n",
      "2236     1\n",
      "15970    1\n",
      "12279    0\n",
      "4230     0\n",
      "1747     0\n",
      "Name: price_higher, Length: 3525, dtype: int64\n",
      "\n",
      "Predicted Labels:\n",
      "[1 1 0 ... 0 0 1]\n",
      "Logistic Regression Accuracy: 0.5492198581560284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.27      0.35      1612\n",
      "           1       0.56      0.78      0.65      1913\n",
      "\n",
      "    accuracy                           0.55      3525\n",
      "   macro avg       0.54      0.53      0.50      3525\n",
      "weighted avg       0.54      0.55      0.52      3525\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "lg = LogisticRegression(random_state=42)\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lg_pred = lg.predict(X_test)\n",
    "\n",
    "print(\"\\nActual Labels:\")\n",
    "print(y_test)\n",
    "\n",
    "print(\"\\nPredicted Labels:\")\n",
    "print(lg_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, lg_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, lg_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
